\chapter{Theoretical background}
\label{chapter:background}

In this chapter, we introduce the necessary theoretical background as well as
explain the reasons why the current work is relevant given the latest
developments in the theory of distributed computing. Unless specified otherwise,
the material presented in this chapter is based on the textbook on distributed algorithms by Hirvonen et al.~\cite{Hirvonen2020}.

\section{Graphs}

This section will outline the necessary theoretical background on graphs. 
Most of the notation related graph theoretic concepts in the current
section and in the rest of the thesis will follow that of
a recent introductory textbook on distributed algorithms~\cite{Hirvonen2020},
unless specified otherwise.

A \emph{graph} is a pair $G = (V, E)$, where $V$ denotes the set of all \emph{vertices}
and $E$ denotes a set of all \emph{edges}. Each edge in $E$ is represented as a set of
2 nodes i.e. the nodes the given edge is connecting e.g. $e = \{v, u\}$ such that 
$v \in V$ and $u \in V$.

When talking about the \emph{size of a graph}, or \emph{cardinality} of the graph, we refer
to the number of nodes in the graph. Or in other words, the size of a graph $G$
is always $|V|$.

Among other things, edges can be categorised into \emph{directed} and \emph{undirected}.
The latter ones simply connect a pair of nodes in a graph, while the latter
ones also contain extra information about which of the 2 connected nodes is
a ``source'' and which one is a ``destination''. Informally, such a directed edge
can be visualised as an error that starts in a ``source'' node and ends in a 
``destination'' node.  Similarly, we talk about \emph{undirected graphs} - that is graphs
where all edges are undirected, and \emph{directed graphs} - such graphs where all
edges are directed. Formally, while an undirected edge $e$ is defined as a
set of two nodes $e = \{v, u\}$, a directed edge $e$ is defined as a pair
of two nodes $e = (v, u)$. Recall that in the case of a tuple, the order of its
elements does matter, hence, the tuple allows us to encode the direction of
the edge. Unless mentioned otherwise, we assume that an edge is directed
from the first element of the tuple to the second. Also note that in this
thesis, unless specified explicitly, all graphs are assumed to be undirected.

If two nodes are connected by an edge, we call such nodes \emph{neighbours}. We
also say that such nodes are \emph{adjacent} to each other. Moreover, in an undirected graph
if there are two edges $e_1$ and $e_2$ such that $e_1 \neq e_2$ and $e_1 \cap e_2 \neq \emptyset$
such edges are said to be \emph{adjacent} to each other. Similarly, we can talk about adjacent 
edges in a directed graph. In that case, two edges $e_1$ and $e_2$ are adjacent if
$e_1 \neq e_2$ and either first or second element of tuple $e_1$ contains the same
element as either first or second element of tuple $e_2$.

Besides we often talk about edges and nodes being \emph{incident} to each other.
In an undirected graph, an edge $e$ is incident to a node $v$ if and only if $v \in e$. In this
case, we also say that the node $v$ is incident to the edge $e$. Similarly, in a
directed graph, an edge $e$ is incident to a node $v$ if and only if $v$ is the
first or the second element of the tuple $e$. Again, in the case described in the
previous sentence, the node $v$ is said to be incident to the edge $e$.

A \emph{simple graph} is an undirected graph where no 2 nodes are connected by more
than one edge and no edge starts and ends at the same node. In other words, there are
no multiple edges or self-loops in a simple graph.

A \emph{degree} of a node $v \in V$ in a graph $G = (V, E)$ is the number of all
edges incident to $v$. That is it is the number of edges such that for an edge
$e$, $v \in e$ if $e$ is an undirect edge, or $v$ is the first or second element of
tuple $e$ if $e$ is a directed edge. Moreover, for directed graphs, we often talk
about \emph{indegrees} and \emph{outdegrees}. Indegree of a node $v$ is the number
of edges incident to $v$ directed towards the node, while outdegree of a node $v$ is the 
number of edges incident to $v$ directed outwards from the node. Finally, we are 
often interested in a maximum degree of a graph $G$, that is the maximum value of
degrees of all nodes belonging to the graph $G$. We denote such maximum degree as
$\Delta$

A \emph{walk} in an undirected graph $G = (V, E)$ is a sequence $w$ of a form
$w = (v_0, e_1, v_1, e_2, ..., e_l, v_l)$,
where $v_i \in V$ and $e_i \in E$, and $e_i = {v_{i-1}, v_i}$ for all $i$. A walk from some
node $v$ to some other node $u$ is then a walk $w$ such that its first element i.e. $v_0 = v$
and its last element i.e. $v_l = u$. Having defined a walk, we can talk about a \emph{
connected graph}. A connected graph, when talking about undirected
graphs, is a graph $G = (V, E)$ in which for any pair of nodes $v$ and $u$ such that
$v \neq u$ there is a walk from $v$ to $u$.

An \emph{isomorphism} between two graphs $G_1$ and $G_2$ is is a function $f$ such that $f$ is a 
bijection, and $f$ maps a vertex of the graph $G_1$ to a vertex of the graph $G_2$, and 
an edge between some nodes $v$ and $u$ exists in the graph $G_1$ if and only if
an edge between nodes $f(v)$ and $f(u)$ exists in the graph $G_2$. From this,
it is rather easy to see that if an isomorphism exists from $G_1$ to $G_2$, then
also an isomorphism exists from $G_2$ to $G_1$. If there exists an
isomorphism between some two graphs, we say that such graphs are isomorphic
(to each other).

A \emph{radius-x neighbourhood} of a node $v$ in a graph $G = (V, E)$ is a set of
all such nodes $u \in V$ that there exists a walk between $v$ and $u$ and 
the shortest walk from $v$ to $u$ is at most $x$. Note that it is possible that
$v = u$, in which case the shortest walk between $v$ and $u$ is 0.

A diameter of a graph (denoted as $\diam(G)$) is the length of the longest walk
in a list $W$, where $W$ is a list of the shortest walks, i.e. the one between each pair of nodes
$v$ and $u$ in a graph $G = (V, E)$ such that $v \in V$ and $u \in V$. If a graph
$G$ is nont connected and therefore there is a pair of nodes $v$ and $u$ that do not
have a walk between them, we say that a diameter of such a graph $G$ is infinity. That
is $\diam(G) = \infty$.

\subsection{Several important graph families}

This subsection will introduce some of the graph families that will be necessary
for understanding the content of the thesis. First, we'll define paths and cycles.
Then, we will briefly introduce trees and explain the difference between rooted
and unrooted trees.

A \emph{path} graph is a sequence of nodes that are joined together by edges and
that have the following properties:

\begin{enumerate}
  \item The whole graph is connected. That is there is a walk from any node of
  the path to any other node of the path.

  \item The graph consists of at least 2 nodes.

  \item Exactly 2 nodes have a degree 1 and all the other nodes have a degree~2.
\end{enumerate}

A \emph{cycle} is a connected graph where each node has a degree 2.

A \emph{tree} is an undirected acyclic connected graph. A \emph{rooted tree}
has a single \emph{root vertex}, and thus some nodes have a \emph{parent} node
(some because e.g. a root node never has a parent) and one or more \emph{children}
nodes. For a node $v$, a node $u$ is its parent if and only if $v$ and $u$ are
neighbour nodes and the shortest walk from the root to $u$ is shorter by exactly
1 compared to the shortest walk from the root to $v$. Node $v$ is a child of node
$u$ if and only if $u$ is a parent of node $v$. Finally, in the context of rooted trees,
a node $l$ that has no children is referred to as a \emph{leaf} node.
On the other hand, an \emph{unrooted tree} has no single root, and therefore the notion of parent
or child is not defined. Instead, we talk about neighbours of some node $v$. However, we 
still use the notion of leaves to denote nodes of degree 1.

\subsection{Biregular trees}
\label{subsection:biregular-trees}

A \emph{bipartite} graph $G = (V, E)$ has its vertices partitioned into two
subset $U \subseteq V$ and $W \subseteq V$ so that the partitioning forms
a proper 2-coloring of the node $V$. In other words, in a bipartite graph $G = (V, E)$,
if a node $v \in U$ then all its neighbours belong to $W$, and if a node $v \in W$
then all its neighbours belong to $U$.

A \emph{regular} graph is a graph where each vertex has the same degree.
A \emph{biregular} graph is a graph where each vertex has one of the two
allowed degrees and only them. In this thesis, when we talk about
\emph{($\beta$, $\delta$)-biregular} graph $G$, we always assume that 
$G = (V, E)$ is bipartite such that $V$ is partitioned into two
subsets $U$ and $W$, nodes in these subsets form a proper 2-coloring,
all nodes in $U$ are of degree $\beta$ and all nodes in $W$ are of
degree $\delta$. In particular, when we talk about \emph{($\beta$, $\delta$)-biregular trees},
we mean a bipartite biregular tree where all nodes except for leaves
follow the rules of ($\beta$, $\delta$)-biregular graphs described above,
but leaves themselves are allowed to have degree 1 (otherwise they would not be
called leaves).

It is important to notice the equivalence of ($\delta$, 2)-biregular trees
and $\delta$-regular trees. Indeed, given a $\delta$-regular tree, we can
``turn'' each edge $e = \{v, u\}$ into a node $v_e$ such that the node is
connected to node $v$ and $u$ and only those nodes. On the other hand,
given a ($\delta$, 2)-biregular tree, we can remove every node $v$ of degree
2 and, given that nodes $u$ and $w$ used to be neighbours of $v$ before its
removal from the graph, connect nodes $v$ and $w$ with an edge.

\section{Distributed computing}

Now that we have introduced some of the key graph theoretic concepts, we will
next outline some of the foundations of distributed computing. We will start with
a short historical node about the field of distributed computing. Then, we will
explain some of the aspects of the model of computation we're concerned with. Finally, 
we will give some formal definitions to the model of computation that will be our
major concern throughout the rest of the thesis.

\subsection{General background}

The field of distributed computing studies computation in distributed systems, which
have become ubiquitous in the modern world, being especially prevalent
in the area of technology~\cite{Attiya2004}.
A distributed system consists of a number of relatively independent
computing modules, which usually need to cooperate in order to
fulfill a computational task the system has been given. Usually,
each computing module in such a system only has a part of the whole
input and is required to produce only a part of the whole output.
This is in contrast with a centralised system, in which there 
exists an all-knowing entity taking all of the input, performing all
of the computation and producing the whole of a result as its output.
Due to its modularised and parallel nature, distributed computing
has many applications in communication, computation, the Internet,
but also in biology and sociology~\cite{Wattenhofer2016}.

The field of distributed computing appeared already in late 1980s, with several
prominent papers exploring potentialities of computation performed
by multiple interconnected processing units~\cite{Cole1986, Linial1987, Naor1991}.
The first major step in the field happened in 1987, when Linial formalised
some of the principles of one variant of a distributed system.
This model of computation is currently known as Linial's or \emph{LOCAL model}~\cite{Linial1987}.

\subsection{Model of computation}

Here, we will describe the model of computation that we are going to
assume throughout the rest of the thesis. Note that there is a number
of different models, which are also widely studied in the research
community.

First, as it was already stated, unlike in the case of centralised
computation, we are concerned with multiple interconnected computing entities
that together form a graph. Each such an entity is referred to as a vertex or
a node in a graph. Connections between the vertices are referred to as edges.
The entities only can transfer information along the edges and in no other way
between each other. Unless specified otherwise, the graphs are assumed to be
simple graphs, and all edges are assumed to be undirected. Moreover,
communication along the edges can simultaneously happen in both direction.

Apart from sending infromation to each other, nodes can also
do local computation based on the local information each node possesses. One thing
to note that differs significantly from some of the centralised models of computation
is that each vertex in a graph has arbitrarily huge, but finite, storage and computation resources.
Informally, this means that anything that can be computed in a centralised setting
in a finite amount of time,
can also be computed locally by a node in an arbitrarily small amount of time.
It is also worth noticing that in the model of computation described here,
every node of a graph executed the same algorithm. Nevertheless, the
algorithm might lead to different commands being executed by different nodes
if, for example, nodes' unique identifiers or initial local inputs are different.
Besides, behaviour might also differ if two nodes have somewhat different neighbourhoods
around themselves and therefore will receive potentially different
information during their communication rounds. Finally, at the beginning of
execution, each node knows only its own input (including its own unique identifier
if such has been provided as part of the input) and its own degree i.e. the number of
its neighbour nodes in the graph.

Furthermore, computation in a graph happens in synchronous rounds. That implies,
for example, that round $x+1$ is not started by any of the nodes before all of the
nodes have completed round $x$. Moreover, each round is divided into three stages:

\begin{enumerate}
\item Sending some information to some (or all) of its neighbours

\item Receiving information
from some (or all) of its neighbours

\item Performing some local computaiton based
on the information that has been stored by a node locally before and the information
received during the current round from its neighbours

\item Updating its local state i.e. replacing and adding data in its own local storage
\end{enumerate}

Each of these stages is also executed
completely synchronously by all nodes in a graph, meaning that e.g.\ no node starts processing
any of its data, before all other nodes have received data from their neighbours. The computation
of a graph is said to be finished when all of the nodes have outputted their final states
and halted. More formally, this means that there are a set of node states that are
considered as ``halting states''. Whenever a node switches its internal state to one of the 
halting state, it does not perform any of the actions from that point in time, or - to
be even more formal - it does not send any messages to its neighbours, ignores all of the 
messages sent to it and does not update its internal state in all of the subsequent rounds.
Similar to the requirement that local computation of each node on each round has to be finite
and needs to stop after a finite amount of time passed, all nodes are required to eventually
transition into one of the halting states. That is a valid distributed algorithm - in our model of
computing - cannot continue for an infinite number of rounds. Finally,
the complexity of a distributed algorithm is measured as number of such synchronous rounds
of computation before the algorithm ends i.e. before all nodes transition into one of 
the halting states. Notice that different from a centralised model of computation,
algorithms complexity (or in other words its running time) is not affected by the
amount of local computation on a single node.

Another important thing that has to be mentioned when describing the mode of computation
is that all of the operations withing each individual node as well as inter-vertex
communication is absolutely error-free. In other words, all nodes can be assumed to
always act in a fault-free manner, all sent messages can be assumed to never be lost
or undelivered. Therefore, we can always assume that messages sent and received by nodes
are all in accordence to the actual algorithm that is being executed by the nodes 
and not a result of an accidental fault or an intentional adversary effort

\subsection{Distinctive qualities of LOCAL model}

As was already mentioned previously, our model of computation is known
as Linial's or \emph{LOCAL model}~\cite{Linial1987}. Therefore, to complete the
description, we will describe in more detail two distinctive qualities of LOCAL model
from other models of distributed computing, namely unique identifiers and arbitrarily large
bandwidth.

Each node in LOCAL model is provided with a unique identifier as part of initial input.
The identifiers are usually assumed to be integer numbers between 1 and $|V|^c$, where
$|V|$ is the number of nodes in the graph and $c$ is some constant. Unless specified, we
assume that such a constant $c$ is not known by the nodes at the beginning of
algorithm execution. Thus, unique identifiers are guaranteed to be positive integer
numbers bounded by a polynomial in the number of nodes, but it is not known - by the nodes
at the start of algorith execution - what is the largest unique identifier in the graph. Moreover,
the identifiers of the node do not necessarily form a continuous range of integers. That is
if an integer $x$ is used as a unique identifier for some node $v$, it is possible
that an integer $x+1$ is not used as an identifier in the graph. This implies that at
the beginning, nodes do not known what integers have been used for unique identifiers
and what have not been, with the exception of only one integer - their own identifier.

Another characteristic of LOCAL model, which also was already mentioned before, is the fact
that nodes can send (and receive) an arbitrarily large (but nevertheless finite)
amount of bytes of information over a single edge during one round. This fact,
combined with the existence of unique identifiers, renders the model as a rather strong one.
In particular, this implies that a node can send all of its information - no matter how
large it is - to all its neighbours in just one round.

This, in turn, implies a rather
curious property. Imagine that every node sends all of its information during the first round,
and having received some data from its neighbours, saves all this information locally. Consider
some node $v$ in the middle of a graph $G = (V, E)$. Since all nodes send all its data,
after the first round, node $v$
will have all the data that all its neighbours had initially, plus its own initial information.
Notice that each of $v$'s neighbours now have all the information of their neighbours. Thus,
if we combine all the data in posession of $v$ and $v$'s neighbours after the first round, it
is easy to observe that they together have all the information of $v$'s radius-2 neighbourhood.
But this means that after the second round, when all $v$'s neighbours have sent all their
information to $v$, $v$ alone posessses all the data that its radius-2 neighbourhood had at the
beginning of the algorithm execution. Similarly, after the 3rd round, $v$ will have all the
radius-3 neighbourhood's data, and so on.
In general, after round $x$, node $v$ will have
all information that was initailly available in its radius-$x$ neighbourhood.
Therefore, when considering LOCAl model,
time and space are in certain sense equivalent. In other words, the number of rounds
needed to solve a certain problem is always equal to the distance (or radius) to which a node needs to
see to solve a certain problem. One technicality to note here is that because all nodes have
unique identifiers, and these identifiers are sent together with the rest of data,
receiving nodes can differentiate what nodes the received data belongs to, and consequently,
reconstruct the structure of the neighbourhood in the graph.

As a consequence of the above,
we can observe that after $\diam(G)$ rounds, node $v$ will have all the information there is in the 
graph $G$. This implies that after $\diam(G)$ rounds, in LOCAL model, we can solve anything that can
be solved in a centralised setting. That is because at the end of $\diam(G)$'th round, each node in the
graph have collected all the information there is in the graph and thus can just run the
computation locally. And because local computation in LOCAL model is virtually free,
anytihng that could be computed in a centralised setting will be computed locally by each
node individually. On the next round, each node can output their part of the solution.

\subsection{Formalising LOCAL model}

In this subsection we will formalise LOCAl model that we informally described above.
This will, first of all, help to clarify the aspects of the model that are still left ambiguous
after reading the previous subsections. Besides, it will allow us to introduce
a randomised model below once the basic deterministic one is unambiguously defined.

An algorithm being executed by each node consists of 
three functions. One for local state initialization that is executed only once, after
a node $v$ has received its initial local inputs $u(v)$ but before the first round

$$init_A(u(v), d)$$
where $A$ is a given distributed algorithm and $d$ is the degree of the node $v$.
The function return an initial local state of the node $v$.

The second function takes as an input an internal state $x(v)$ of a node $v$
and returns a tuple of size $d$, where $d$ is a degree of node $v$. The
tuple contains messages that are to be sent to $d$ neighbours of the node $v$
during the current round.

$$send_A(x(v), d)$$

The third function takes as an input a local internal state $x(v)$ of a node
$v$, and a tuple $m(v)$ of size $d$ that contains messages received from $d$ neighbours
of the node $v$.

$$receive_A(x(v), m(v), d)$$
The function returns a new local internal state of the node $v$, which becomes a
starting internal state $x(v)$ in the next round.

\subsection{Randomised algorithms}

This subsection will introduce a randomised distributed model of computation
and highlight some of the difference between randomised and deterministic
models. In this section, the focus will be specifically on randomised LOCAL
model as opposed to some other distributed algorithms models.

In a randomised LOCAL model, we have two major differences from the
deterministic LOCAL model. First, the function $init_A(u(v), d)$ becomes
randomised. This means that the initial state $x_0(v) = init_A(u(v), d)$ of a node $v$ is
chosen from a discrete probability distribution of all possible initial states.
Second, the function $receive_A(x(v), m(v), d)$ becomes randomised. This means that,
after all messages have been sent and received for round $i$, a new local internal
state $x_i(v) = receive_A(x(v), m(v), d)$ for a node $v$ is selected from a
discrete probability distribution. Everything else in the model remains exactly
as it is in the deterministic case, that is no changes are made to the $send_A(x(v), d)$
function.

Since probabilities are involved when in randomised setting, it might not be
drectly obvious what it means to ``solve'' a problem. The major problem is that
since states of the nodes are chosen from a discrete probability distribution,
there is always a probability that the output of the nodes will not be valid.
Therefore, there is often a probability that the problem has not been solved
after a certain number of rounds.

But before we define what it means to solve a problem in a randomised setting, it's
worth noting that there exist two kinds of randomised algorithms: ``Monte Carlo'' and
``Las Vegas''. \emph{Monte Carlo} algorithms always stop after a specified $f(n)$
number of rounds, where $n$ is the number of nodes in the graph, but
it is not guaranteed that the output will a valid one. Monte Carlo algorithm
only guarantee their execution time, and succeed only with probability $p$.
\emph{Las Vegas} algorithms, on the other hand, always produce a correct output,
once all the nodes in a graph have stopped, but the algorithm will stop after a
specified $f(n)$ number of rounds only with some probability $p$. Thus, in some
way, these types of randomised algorithms are complements of each other:
one guarantees correctness of the output but has a chance of going over some
specified execution time, while another has a guarantee on the execution time
but has some probability of producing incorrect output. In the rest of the thesis,
unless explicitely specified otherwise, we assume that the randomised algorithms
are Monte Carlo algorithms.

Finally, we now can define what it means to solve a problem in a randomised context.
When saying that a certain randomised algorithm ``solves'' a cerrtain problem in
$T(n)$ rounds, unless specified otherwise, we mean that the algorithm stops after
$T(n)$ computational rounds and the nodes output (or to be more precise the nodes
have transitioned to one of the output states) a correct solution ``with high
probability'' (often denoted as ``w.h.p.''). Formally, if an algorithm succeeds with
high probability, it means that the algorithm succeds with probability of at least
$1 - 1 / n^c$, where $n$ is a number of nodes in a graph and $c$ is some constant
such that $c > 0$. Moreover, $c$ is a constant that can be freely chosen when 
running the algorithm. To give a simple example, algorithm's running time may
linearly depend on such a constant $c$, then before an algorithm is executed,
one may freely choose the constant so that the larger the constant the longer is
the running time, but also the lower the chance that the produced output will
be incorrect. Notice that $c$ does not need to affect running time, but it often
does since the larger it is the lower is the probability of algorithm's failure,
and decreasing such probability usually comes at the cost of something else - 
often running time. Thus, when saying that something succeeds ``with high probability''
we not mean it vaguely but rather refer to a very precise mathematical definition 
given above.

\section{Iterated logarithm}

This section will introduce the iterated logarithm function. The function is
one of the most common complexity results of distributed algorithms and will
appear often in the rest of the document.

The interated logarithm function, denoted as $log^*(x)$ is defined as follows:

\[
    \log^*(x) = \begin{cases}
        0 & \text{ if $x \le 1$}, \\
        1 + \log^*(\log_2 x) & \text{ otherwise}.
    \end{cases}
\]
The function is notable for the fact that it grows extremely slow. For example,

$$log^*(1) = 0$$
$$log^*(2) = 1$$
$$log^*(4) = 2$$
$$log^*(16) = 3$$
$$log^*(65536) = 4$$
$$log^*(2^{65536}) = 5$$

\section{Locally Checkable Labelling problems}

This section will introduce locally checkable labelling problems (from now on referred to as
LCLs), which are the main focus of this thesis. The section will start with
a short historical note and then provide a formal definition of
LCL problems.

As the field of distributed algorithms started to develop, it became clear
that some classes of problems
are of a particular interest to the theoretical research community.
One class of such problems has been first introduced in 1993 by
Moni Naor and Larry Stockmeyer under the name of Locally Checkable 
Labelling (LCL) problems~\cite{Naor1993}.

In short, an LCL problem is a distributed problem that satisfies the 
following criteria~\cite{Naor1993, Suomela2020}.

\begin{itemize}

\item the maximum degree of a graph is a finite number that does not depend on $n$

\item there is a finite number of input labels and the number is not dependent on $n$

\item there is a finite number of output labels and the number does not depend on $n$

\item the correctness of a solution can be checked locally by each individual node. That is
after a solution is produced and all the nodes in the graph have stopped, each node can just
check a radius-$O(1)$ neighbourhood around itself. The solution is valid if and only if each of
the individual neighbourhoods for all the nodes are valid.

\end{itemize}
In the list above, $n$ is the number of nodes in the graph. Finnally, as is easy to see from the definition of LCL
probles
above, there is always a finite representation of any LCL problem. Indeed, one can simply list
all valid local neighbourhoods, list all valid input labels, list all valid output
labels and specify the maximum degree of a graph. Since all of the beforementioned are
of size $O(1)$, it is always possible to have a finite representaion of an LCL.
In practive however, it is in many cases more practical to come up with
a moe concise representation. We will return to the topic of representing LCL
problems later in this thesis.

The study of LCL problems has been one of the major research directions
during the last 6-7 years, with numerous papers published in major
distributed computing conferences
~\cite{Balliu2016, Chang2016, Brandt2017, Chang2017, Fischer2017a, Rozhon2019, Balliu2020-1, Balliu2020-2}.
Currently, the study of LCL problems has reached the stage of maturity with,
for example, the complexity landscape of LCL problems understood
almost entirely ~\cite{Suomela2020, Chang2020a}.

\section{Major LCL problems}

This section will introduce some of the common LCL problems
widely studied in distributed algorithms research community.
Note that all of the problems also exist in the context of 
centralised computing.

\textbf{Vertex coloring} is perhaps one of the most well-known
problems on graphs. Informally, the goal is to color a graph
in such a way that no two adjacent nodes are colored with the
same colors. It is also easy to see tshat the problem is an
LCL problem because it is sufficient and necessary for each node to check
its radius-1 neighbourhood. If each node's radius-1 neighbourhood is
a valid one i.e. none of the neighbours of node $v$ have the same color as $v$
itself, then and only then the output is a valid vertex colorings

Another well-known and widely studied problem on graphs is
\textbf{edge coloring}. Informally, each edge needs to be
colored in such a way that no two adjacent edges are of the same
color. Coloring edges in a graph can still be simulated
with the setting in which only nodes output the labels.
Each node will output a tuple of the size equal to the node's
degree. Each element of a tuple represents a label
that the node outputs on a coresponding edge. The problem
is also an LCL problem, because after a final output is
produced, each node $v$ will need to check its radius-1
neighbourhood to make sure 2 things are in order:
\begin{enumerate}
  \item All edges incident to $v$ have to be of different color.
That is no two elements of node $v$'s output tuple should be the same.

  \item For each edge incident to $v$, a color that node $v$ colored some incident
edge $e$, should be the same as the color that node $u$ colored the edge $e$ with.
Here $e = \{v, u\}$. In other words, because each edge's coloring depends on
output of 2 nodes, such coloring has to be consistent for each edge i.e. the produced
colors need to be the same on both ends of each edge.
\end{enumerate}

An \textbf{independent set} is a problem in which some subset of vertices in a graph
join a set $I$ and some do not. The restriction is that no pair of vertices in the set $I$
can be adjacent nodes. A \textbf{maximal independent set} is a restriction of the
problem in which in addition to what has been stated above, there is an additional
maximality restriction. Maximality restriction forbids cases where a node $v$
is not in the set $I$ but also does not have any adjacent nodes in the set $I$.
In other words, in \textbf{maximal independent set} all nodes either belong
to the set $I$ or they \emph{cannot} join becuase one of their neighbours has
already joined. It is trivial to see that the problem is an LCL as checking local
eighbourhood will suffice to determine if the solution is valid or not.

Finally, a \textbf{maximal matching} is a problem in which nodes need to
produce a matching such that each node is either matched with one of 
its neighbours or it cannot be matched because all of its neighbours are
matched. That is no node can be left unmatched while at least one of its
neighbours is unmatched. It is trivial to see that the problem is an LCL
since each node can check its radius-1 neighbourhood to check whether it
is matched with a neighbour or all neighbours are matched with someone else.
And if the condition of the previous sentence is not satisfied, the output
is invalid.

\section{Recent developments in automated classification of LCL probems}

At this point that the theoretical background has been given, it is
useful to give a background to much more recent developments in the
distributed algorithms research. As the branch of research
studying LCL problems had been reaching maturity, many focused
on the idea of autmated classification of LCL problems. That is
the question of interest is whether we can create meta-algorithms
that would take a description of an LCL problem as its input
and produce the problems round complexity as an output.
This being the core topic of the thesis, it is thus important
to describe all the prior work done in this direction.
In the rest of the
section, we will introduce some of the negative as well as positive results
related to automated classification of LCL problems.

The questions of whether a certain class of LCL problems
can be automatically classified are often referred to
as decidability question. Roughly speaking, a problem is
said to be decidable if there exists an algorithm that,
given the problem, will output its complexity. Such decidability
questions are often studied in relation to the whole
family of graph problems and not to individual instances
of problems.

First of all, it is important to notice that it has been
proven that in general LCL problems are undecidable.
In fact, already in the cases when the graph family is a grid,
LCL problems cannot be automatically classified~\cite{Brandt2017, Naor1993}.

Nevertheless, many interesting LCL problems are still decidable.
For example, it was known for several years now that LCLs
on paths and cycles are decidable~\cite{Balliu2018, Brandt2017, Naor1993}.
Besides, certain types of LCL problems are also decidable on
trees~\cite{Chang2017}.

But the fact the a problem is decidable in theory does not
always imply that it is possible in practice to
construct an algorith for automatic classification of
such problems. For instance, it is known that even in
the case of paths and cycles, if a node labelling is
given as part of the input, decidability becomes
PSPACE hard~\cite{Balliu2018}.

However, not everything looks that gloomy, and many
interesting and sufficiently broad families of LCL
problems are both decidable and possible to
automatically classify in practice. Indeed a lot of work
has been done attempting to derive practival algorithms
that determine complexity of a given LCL problem,
especially in trees.

Balliu at al. has shown that a complete classification
of binary labelling problems (problems where a node's
output is allowed to be only one of the two possible labels)
at least in a deterministic setting is possible and moreover
can be done in $O(1)$ time, since computational
complexity of such problems can be simply looked up in a
table in a constant time ~\cite{Balliu2019c}. In addition
to this, the paper also shows tha it is decidable to
classify at least \emph{some} of the randomised binary labelling
LCL problem~\cite{Balliu2019c}.

Building on top of the work outlined in the paper, Rocher
has developed a meta-algorithm that classifies \emph{almost}
all ternary labelling problems on trees in deterministic
setting~\cite{Rocher2020clas}. Furthermore,
he also implemented the meta-algorithm as a
computer program written in Python programming language~\cite{Rocher2020doc}.
Although the implementation focuses mainly on the case of trees with degree 3,
the techniques described in the manuscript are applicable to ternary problems
on trees of higher degrees as well.

In addition to this, LCL problems on trees and cycles
are fully decidable in polynomial time as was shown by Chang et al.~\cite{Chang2020}.
The algorithm for classifying the problems can be used in practice and has
been implemented in Python programming language by Aalto's
Distributed Algorithms research group~\cite{Tereshchenko2020}.

Finally, a technique called Round Elimination was introduced in the context
of LCL problems by Brandt et al~\cite{Brandt2019}. It is a series of mechanical
steps that, if followed, in many cases transform an LCL problem $\Pi_0$ into another LCL problem $\Pi_1$. An interesting property is that, given certain assumption and the fact that
$\Pi_0$ is solvable in constant time e.g. in $T$ rounds, $\Pi_1$ is guaranteed to be
solvable in exactly $T - 1$ rounds. This single property has numerous implications.
For example, if we apply the technique $n$ times and in the end obtain an LCL problem $\Pi_n$
such that it is zero-round solvable, we know that the original problem $\Pi_0$ is
exactly $n$-round solvable. Furthermore, Round Elimination is not only possible
in theory but is also very much feasible in practive. Indeed, Olivetti has
implemented a computer program that, given an LCL $\Pi_0$ solvable in $T$ rounds,
it produces another LCL $\Pi_1$ solvable in $T - 1$ rounds. There even exists
a web interface for the program, and one can apply the technique and obtain
its results within milliseconds. We will describe the technique and its implications
in much more detail in the subsequent section.

<Add section about yet-to-be-published manuscript by Jan, Alkoda, Sebastian, et al.
which would give full rand and deterministic classification for problems on binary
rooted trees.>
