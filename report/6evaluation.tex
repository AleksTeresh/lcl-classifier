\chapter{Evaluation and opportunities for further development}
\label{chapter:evaluation}

In this chapter, we will attempt to evaluate success of our implementation
based on the research goals and the scope that we have outlined in Chapter~\ref{chapter:methods}.
Besides, we will also evaluate performance of the implementation. As seen from the title,
we have decided to combine the evaluation with discussion on opportunities for further
development. Therefore, we will also propose several ideas for how our implementation
can be improved and extended.

The first goal among the research goals listed in Chapter~\ref{chapter:methods}
was to store (or be able to compute dynamically) most
(if not all) of the existing knowledge on classification of LCL problems on trees.
To evaluate how well we have done, we can refer once again to Table~\ref{table:summary}.
The first three columns under the "Paths and cycles" grouping refer to LCL problems on
paths and cycles where input is not allowed. The graphs can be directed or undirected,
have arbitrary (but finite) number of labels in the output, and have restrictions
on nodes of degree 1 (in cases of paths). All of these cases are covered by
the cycle-path classifier~\cite{FIXME}, which is based on the recently
published paper~\cite{FIXME}. The classifier has been integrated into our
solution an, thus, we claim that the problems of this family are fully classifiable by our tool.
The forth column of the table refers to LCL problems on paths and cycles
where input labelling is allowed. Since none of the used classifiers
are capable of processing problems with inputs, this family of problems
has not been covered by our implementation, although it has been shown that
LCLs of this class are decidable (even though it is PSPACE-hard)~\cite{Balliu2018}.
% go through other columns
% summarize in the end what families of problems we have failed to cover

% store most/all existing knowledge about complexity of LCL problems on Trees
% Does it work on all trees?

% get Complexity of a problem X

% return all problems on e.g. binary rooted trees that have complexity e.g. log* N

% references to sources


% all meta-algorithms used?
  % RE (label limitations?)
  % cycle-path classifier
  % binary label classifier (Rust implementation by Dennis)
  % TLP classifier (degree limitations?)
  % rooted tree classifier (by Jan) (only binary?)
  % BRT dataset


% currently label count is UB. People want to be able to specify a LB for labels used
% people want to query for only fixed-points problems
% people want to query for problems of exact constant complexity
% restrictions on what output nodes can produce is currently somewhat limited (at least there is no differentiation between active/passive nodes)


% speed of classifying a problems

% speed of getting batch query resutls

% speed of batch classification

% number of preclassified problems in the database
   % how many of them are not trivially classified

