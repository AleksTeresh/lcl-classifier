\chapter{Implementation}
\label{chapter:implementation}

This chapter will describe the implementation of the tool.
In particular, we will outline high-level architecture of
the software, disciss internal representation of
LCL problems as well as representation of the query object.
Moreover, we will discuss how batch classification has been
implemented. Finally, in the end of the chapter we will cover
several miscellaneous items such as problem normalization
algorithm, integration of Round Eliminator tool into
our software and some of the properties of the user Web interface,
which has also been implemented as part of the thesis project.

\section{General architecture of the tool}

This section will outline general architecture of the tool and
will describe in further detail some of its most important
components. Despite the chapter's name, we are not going
to describe low-level implementation detail in this section,
but instead try to convey technical perspective on the tool
as a whole. We will also discuss and critically analyze some
of the architectural and technological decisions that have been
made during the implementation phase.

On the high level, the software consists of three parts:
front-end application, back-end application and a database.
The database contains arguably the most important component
of this project -- definitions of LCL problems as well as their
known upper and lower bounds. The back-end part contains
the core logic for classifying LCL problems. Besides, it acts
as a middle layer between the database and the front-end part.
That is, it is responsible for receiving data from one of the
components (e.g. database), transforming it to the
format understandable by the other part (e.g. the front end),
and finally sending it to that part. Finally, the
front-end part's main responsibility is to provide
an understandable and user-friendly user interface
through which one could classify individual LCL problems
as well as query for the whole families of problems
that satisfy specified criteria. Furthermore,
the clint-side part of the application is
resonsible for displaying the results returned by the
back-end part in a concise and understandable manner.

The database contains only three tables: one for
storing LCL problems together with their upper and
lower bounds, one for keeping track of what families of
problems have been generated and classified via batch
classification mechanisms, and one storing meta-data
of the meta-algorithms used in classifying the LCLs.
The front end is quite simple from technical perspective
too. Some of the details about the client side of the
application will be discussed more in Section~\ref{section:webinterface}.
The back end, however, contains most of the compplexity of
the tool. Therefore, in this section, we will concentrate
mainly on the sever side.

\subsection{Problem}

The core element of the whole application and of the
back-end part in particular is the Problem class.
For representing an LCL problem, we have decided
to use notation similar to that of Round
Eliminator. Our representaion however also
allows for graph types other than trees -- namely cycles.
Besides, it allows the underlying graph of a problem
to be rooted (or directed in the case of cycles).
Finally, it allows representing problems where
leaves' and root's out labels are also constrained
(unlike in the case of homogeneous problems).
The representaion similar to that of a Round
Eliminator has been chosen because of its generality.
In particular, as we have shown in Theorem~\ref{theorem:re_formalism_is_general},
any LCL problem
on $(\beta, \delta)$-biregular unrooted trees -- provided
that nodes of degrees other than $\beta$ and $\delta$ are unconstrained
and nodes near leaves are unconstrained -- can be represented
using the formalism used in the Round Eliminator.

Since we are only concerned with problems on regular trees and cycles
this representation works well for us. For the cases of cycles,
the only restriction is that degree of both passive and
active configurations has to be two. Also, the case
of directed (rooted) cycles (trees) can be handled
using the "colon notation" that has been already
previously used in a recent paper on automating
the classification of LCLs in rooted trees~\cite{Balliu2021}.
Furthermore, the cases when "irregular" nodes, i.e.
leaf nodes or root node, are restricted can also
be handled by specifying those restrictions
(separately for leaf nodes and a root node)
as separate properties of the Problem object.
Thus, our representation of LCL problems is general
enough to cover all the LCL problems that are
included in the scope of the project.

Having explained this, we can finally list all the
properties that are encapsulated into the
Problem object. The object contains the already
mentioned active configuration, passive configurations,
leaf constraints (which can be an empty set), root constraints
(which can be an empty set too), as well as special flag variables
indicating whether all active or all passive configurations
are allowed for active and passive nodes respectively.
If one of the two flag variables are set to true,
it overrides whatever is contained in the variables
holding the actual active and passive configs.
Besides, each problem object contains information
on the type of the underlhing graph: path, cycle or
tree. Notice that although any path is always a tree,
we chose to differentiate between those two
for convinience. It is worth mentioning that
a path graph type will be chosen as internal
representation whenever both active and
passive configurations are of degree two and
the user-selected graph type is not cycle.
In particular, if a user specifies tree as a graph
type and provides configurations of degree two,
tree will still be chosen as a graph type of the problem
internally. Finally, after parsing the configs
that are always provided in a string format,
the tool automatically decides whether the given problem's
underlyhing graph is rooted/directed or not.

It is also worth noting that as a first step of
creating a Problem object, the specified parameters,
including nodes' configurations and constraints
are checked for validity. Thus, if, for example,
a problem is misspecified so that some of the
configurations are "directed" while others are not,
an exception is thrown containing a message with
a human-readable explanation for why the
specification was invalid. After the validity
of the specification is checked, a problem is
normalized by executing the normalization algorithm
described below in Section~\ref{section:problem-normalization}.

\subsection{Classification}

Another central component of the back end is
the function responsible for classification of LCL problems.
On the high level, the function takes as input an LCL problem and
runs underlying meta-algorithms, some of which might be
able to provide some useful information about the complexity of the
problem. After that, the function combines the results
returned by all the meta-algorithms. Based on teh results returned,
the function determines the tightest known lower and upper bounds of
the LCL problem both in the deterministic and randomised LOCAL
models. Finally, a Response object is constructed based on the bounds
and is returned as the functions result. In the best case, tight
complexity bounds are found for both deterministic and randomized
settings. In the worst case, trivial bounds are returned:
"unsolvable" for upper bounds and $\Omega(1)$ for lower bounds.

Each of the underlying meta-algorithms or datasets is wrapped
in a function -- we will refer to it as "subclassify" from now on -- such
that it provides unified interface for the main
"classify" function. In particular, subclassify takes
as input an instance of the Problem class and
returns an instance of Response class. A Response object
simply encapsulates upper and lower bounds for both
deterministic and randomized settings. There is
exactly one subclassify function for each meta-algorithm
or dataset that we use. Inside each subclassify function,
we first check if the provided problem can be classified
at all by the underlyinng meta-algorithm. Often, we can
exit early already at this stage if, for examle, the meta-algorithm
in question deals only with rooted trees and the provided input is a 
problem on unrooted trees (or e.g. a problem on cycles). Then,
if we haven't exited the function yet,
we transform an instance of the Problem class to a problem
representation used by the meta-algorithm that the given
subclassify wraps around. The meta-algorithm is then executed,
the retured result is transformed into an instance of the
Response class and the Response object is returned as
a result of the subclassify function.


\subsection{Query}

% query itself (query representation)
% querying functionality

\section{Problem normalization}
\label{section:problem-normalization}

This section describes the above mentioned problem normalization
algorithm. The algorithm is used for determining which problems
are equivalent to each other. This, in turn, allows us
to reduce the amount of needed storage. Besides, this prevents
situtaions when a tool needs to run classification for a problem $A$
from the very beginning while an isomorphic problem $B$ has already been classified
by the tool previously and saved in the database. Thus, the normalization
algorithm also allows us to reduce the usage of computational resources.

The algorithm is based on the problem normalization algorithm
from Round Eliminator~\cite{FIXME}. While the original
algorithm is written in Rust programming language, we
reimplemented it in Python and changed some of its
implementation details to better suit our purpose.
However, the general idea of the algorithm stays the same.

First, we determine how many labels are used in the description of the
problem $P$ i.e. its alphabet size. Then, we map each letter in the description
to a letter from A to Z. For example, if numbers were used for describing
the problem, the numbers will be mapped to capital letters of
English alphabet. It is important to point out already now that
one limitation of the current implementation is the fact that
a problem with more than 26 labels cannot be correctly normalized.
Once we obtain the list of letters used, we calculate all
permutations of the list. For each permutation, we execute the following
subroutine:

\begin{itemize}
  \item Based on the given permutation, create a mapping from each
  element of the problem's alphabet to each symbol in the permutation.
  That is, we map the $i$'th letter of the $P$ alphabet to the $i$'th symbol
  in the permutation for all $i$ from 1 to the size of $P$'s alphabet.
  \item Based on the obtained mapping, do the following with the problem's
  active configurations, passive configurations, leaf constraints and
  root constraints one at a time.
  
  \begin{itemize}
    \item For each line of the configurations/restrictions, rename symbols
    according to the mapping constructed above.
    \item If the problem $P$ is specified on unrooted/undirected graph,
    change position of all symbols on each line of the configurations/restrictions according to symbols alphabetical order.
    If the underlying graph of $P$ is directed/rooted, keep the currently first
    symbol as first, but change positions of all the rest symbols (again separately for each line)
    according to symbols alphabetical order.
    \item If at this point, some configuration lines are
    duplicated, remove all the duplicates so that each configuration
    line is unique.
    \item Sort the unique configuration lines in alphabetical order
    treating the lines as strings.
  \end{itemize}

  \item Return the newly constructed active configurations,
  passive configurations, leaf constraints and root constraints as
  a tuple of four elements.
\end{itemize}

Each execution of the subroutine described above yields a tuple
of size four. Thus, after executing the subroutine on each permutation of
labels, we eventually obtain a list of tuples of size four.
Then we sort the list, and take its first element. The four
tuple's elements are then assigned to the $P$'s
active configurations, passive configurations, leaf
constraints and root constraints respectively.

% \begin{algorithm}
% \DontPrintSemicolon
% \caption{\label{alg:normalize}normalize($P$)}
% \KwIn{problem $P$}
% \KwOut{problem $P$ with its constraints and configurations normalized}

% $lc \gets$ number of labels in $P$ \;
% $ls \gets$ first $lc$ capital letters of English alphabet \;
% $perms \gets$ a list of all permutations of $ls$  \;
% $all_normalized \gets$ empty array \;
% \For{every $perm$ in $perms$} {
%     add $normalizeForPermutation()$ $all_normalized \;
% }

% this is just an example 


% \Repeat{$R_{i} = R_{i-1}$}{
%   $i \gets i + 1$\;
%   $R_{i} \gets R_{i-1}$\;
  
  
% \uIf{$(\Sigma_\Pi,a \neq \epsilon) \in R_i$ and $\Pi$ is non-empty}{
%   \Return $\Sigma$
%   }
% \Else{
%   \Return $\epsilon$
% }
% \end{algorithm}


% \section{Batch classification and reclassification}



\section{Integration of Round Eliminator}

This section describes how the Round Eliminator
tool~\cite{FIXME} has been integrated in our solution.
Prior to integration we had had considered several options:

\begin{itemize}
  \item Using an API of a server that runs the back end of the Round Eliminator tool
  \item Calling REtor as a command line tool from our Python
  application and then parsing the output, which is returned
  in a text format as part of stdout~\cite{FIXME}
  \item Compiling REtor's source code to a "Shared Object" file (.so extension)
  using CPython ~\cite{FIXME} bindings and then importing the compiled
  functions to our Python application as CPython dependency.
\end{itemize}

At the moment of writing the thesis, the Round Eliminator tool
is deployed using WASM~\cite{FIXME}. This virtually means that
there is no back-end part running on a server, but instead
all of the logic is executed on the client side of the application.
Redeploying the tool with a standalone server and a separate client
part did not seem like a feasible alternative since this would
require a nontrivial amount of work from the tool's maintainers.
Thus, the first option was not feasible.

On the other hand, the second option was feasible. Indeed,
this method of using REtor had already been used in the
implementation of TLP Classifier~\cite{FIXME}. However,
this approach has several crucial disadvantages.
Firstly, the overhead of calling a command line command
from a Python program is significant compared to just calling
a Python function. Secondly, the output of Round Eliminator
would have to be parsed from the plain textual format, which
would have added an additional complexity of the software.
Finally, the approach complicates distribution and deployment of
the software. Indeed, one would have to install the specific
version of Rust programming language as well as download and
build form source codes the specific version of REtor required.

Instead, we have decided to go with the latter option. This
alternative does not have any of the disadvantages listed
in the previous paragraph while being just as feasible and
easy to implement. Compiled in this manner, the whole of
Round Eliminator logic is contained in a single .so file
that can be easily deployed to e.g. a production server.
Besides, the speed improvement is significant: we were
able to execute up to 3 rounds of round eliminator
in under 100 milliseconds. Finally, the functions
exposed via the .so file, return python-native
data structures so that no additional parsing is required on our side.
This, in turn has been achieved by adding CPythin bindings
to the REtor source code. The bindings wrap the relevant functions
written in Rust, thus enabling us to pass Python data structures
as parameters and recieve the return values as python-interpretable values.
The bindings were implemented using the rust-cpython library~\cite{FIXME}.


\section{Web interface}
\label{section:webinterface}

This section will briefly discuss some implementation details of
the client side of the application. First, we start explaining why
the web interface has been implmented in the first place and why it
is important. Then, we describe some of the technologies that were
chosen as part of the implementation. Finally, we describe the
reasoning behind and advantages of the forms' state being stored
as a query part of the URL.

The reason why we decided to spend additional time and implement
the web interface can be best unnderstood when considering
another tool that has recently been rising in popularity among
the distributed algorithms community -- Round Eliminator~\cite{Olivetti2020}. The tool has proved to be a very useful utility
when doing research connected to LCL problems on biregular trees.
However, if it wasn't for the web interface that Olivetti has
implemented, it is most likely that the popularity and
frequency of use of the tool would have been nowhere near the current
levels. Indeed, almost all users of the tool use it via the web
client. Otherwise, a user would need to install Rust programming
language~\cite{FIXME}, build the tool locally using the tool
called "Cargo"~\cite{FIXME} and then run it using the command-line.
It is clear that the number of people willing to do that would be
significantly smaller than number of people who ended up using
an easy-to-use web interface that requires no installation or 
configuration.

By analogy, we can assume with high confidence that significantly more
user would be willing to use our tool vie the web interface rather
than downloading the soource of the tool locally and installing
a specific version of Python programming language~\cite{FIXME}.
Moreover, the richness of the web user interface allows us to convey complicated
ideas related distributed computing in way that is easier to understand, at least for knowledgable audience. Thus, it is has been
decided to spend some time resources -- even though they were 
quite limited -- on implementing a web user interface that is
relatively easy to use and understand compared to its
command line -based analog.

The web interface consists of two forms. One form for classifying
individual problems, and another one for issueing queries
about groups of problems against the database. When using the
first form, our application will first check if the requested
problem can be found in a database. If not, it will proceed to
running the classifiers (which corresponds with the "classify" function described above) and will eventially return the newly
classified result. If the classification result is not trivial (which means that lower bounds are constant and upper bounds are unsolvable),
it will also be stored in the database. The second "query" form, once
submitted will be transformed into the previously described
"Query" object. The query will then be executed against the database,
the results will be returned to the client side and rendered
in a user-friendly format.

As a programming language for our front-end application, we decided
to use TypeScript~\cite{FiXMEs}. TypeScript is a general purpose
programming language developed and maintained by Microsoft~\cite{FIXME}. It is closely related to JavaScript programming language~\cite{FIXME}, which has become de facto standard programming language for the Web.
As a framework for our client application, we have decided to use
Svelte~\cite{FIXME}. Svelte is an open-source front-end framework
written in TypeScript. Among other things, it allows a simplified
approach for application state management, and reduces initial
page load times compared to other front-end frameworks~\cite{FIXME}.

For the styling of the front end, we used a minimalist CSS framework
called "Milligram"~\cite{FIXME}. It provides a good starting point
when it comes to styling a modern web application. Besides, the total
size of the framework is just 2 kilobytes when zipped~\cite{FIXME}.
This, simplicity to use, and our previous positive experience with
the framework were the decisive factors that influenced our final
choice.

As a final interesting piece of technology used, we describe properties
and our reason for choosing to use svelte-virtual-list~\cite{FIXME}.
The library allows rendering only part of the content instead of rendering
the whole of the content on a web page. In our case, this is
particularly useful as it allows us to
show tens of thousands of LCL problems (returned as part of the described above querying functionality) in a virtual list.
The virtual list, implemented via the above mentioned svelte-virtual-list library, renders only a small number (about 3-4)
LCL problems at the same time. At the same time, it allows user to
scroll through the list of problems with no noticable delay.
If not for the library, our client application would have to render
tens of thousands of LCL problems all at once. This would result in
the user interface freezing for a prologned period (up to several minutes).

Finally, we will explain the reasoning behind and benefits for
storing the state of the two forms as part of the URL's query
component. When searching for interesting query results, or even
just classifying different individual LCL problems, it is often
required to demonstrate the results to somebody else. To allow for such
a sharing, we decided to encode the state of both forms in the URL.
Thus, once e.g. the results of a query are obtained, it is possible
to copy the link and simply send it to, for example, a colleague.
When opening the link, both forms will be prefilled with
exactly the same values as those of the sender. This will make sure
that in most cases the sender and the reciever of the link will end
up with the same results displayed. Besides, if a particularly
interesting query has been discovered, it is possible to
simply copy and store the link. Opening the link in the future,
will prefill the forms with the same parameters and display
the same relevant results.


% \section{Deployment details}
